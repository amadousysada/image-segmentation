# Mod√®les de Segmentation S√©mantique

Ce repository impl√©mente deux mod√®les recommand√©s pour la segmentation s√©mantique, ainsi que plusieurs fonctions de perte avanc√©es pour optimiser les performances.

## üìã Table des Mati√®res

- [Mod√®les Impl√©ment√©s](#mod√®les-impl√©ment√©s)
- [Fonctions de Perte](#fonctions-de-perte)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Exemples d'Entra√Ænement](#exemples-dentra√Ænement)
- [Structure des Fichiers](#structure-des-fichiers)
- [Performances Attendues](#performances-attendues)

## üèóÔ∏è Mod√®les Impl√©ment√©s

### 1. U-Net Mini (Mod√®le de Base)

**Caract√©ristiques :**
- Architecture U-Net simplifi√©e sans pr√©-entra√Ænement
- ~1.7M param√®tres
- Temps d'entra√Ænement rapide
- Consommation m√©moire r√©duite

**Avantages :**
- Id√©al pour le prototypage rapide
- Peu de ressources GPU requises
- Simple √† comprendre et modifier

**Usage recommand√© :**
- Tests et validation rapides
- Environnements avec ressources limit√©es
- Baseline pour comparaisons

### 2. VGG16-UNet (Mod√®le Avanc√©)

**Caract√©ristiques :**
- Backbone VGG16 pr√©-entra√Æn√© sur ImageNet
- ~21M param√®tres
- Architecture U-Net avec skip connections
- Transfert learning efficace

**Avantages :**
- Performances sup√©rieures attendues
- B√©n√©ficie du transfert learning
- Encodeur robuste et √©prouv√©

**Usage recommand√© :**
- Production et performances optimales
- Datasets de taille moyenne √† grande
- Quand la pr√©cision est prioritaire

### 3. ResNet50-UNet (Bonus)

**Caract√©ristiques :**
- Backbone ResNet50 avec connexions r√©siduelles
- ~35M param√®tres
- Architecture moderne et performante

## üéØ Fonctions de Perte

### 1. Cross-Entropy Standard
```python
loss = 'sparse_categorical_crossentropy'
```
- Fonction de perte baseline
- Simple et stable
- Bon point de d√©part

### 2. Dice Loss
```python
loss = dice_loss
```
- Optimis√©e pour la segmentation
- G√®re bien l'imbalance de classes
- Focus sur le chevauchement des r√©gions

### 3. Focal Loss
```python
loss = focal_loss
```
- Excellent pour les classes d√©s√©quilibr√©es
- R√©duit l'importance des exemples faciles
- Param√®tres `alpha` et `gamma` ajustables

### 4. Combined Loss (Dice + Cross-Entropy)
```python
loss = combined_loss
```
- Combine les avantages de Dice et Cross-Entropy
- Poids ajustables entre les deux composantes
- Souvent la meilleure option

### 5. Balanced Cross-Entropy
```python
loss = balanced_cross_entropy
```
- Pond√®re les classes selon leur fr√©quence
- Poids pr√©d√©finis pour Cityscapes
- Am√©liore la d√©tection des classes rares

## üöÄ Installation

1. **Cloner le repository :**
```bash
git clone <repository-url>
cd segmentation-models
```

2. **Installer les d√©pendances :**
```bash
pip install -r requirements.txt
```

3. **V√©rifier l'installation :**
```python
import tensorflow as tf
from models import create_model
print("Installation r√©ussie!")
```

## üíª Utilisation

### Cr√©ation d'un Mod√®le

```python
from models import create_model, compile_model

# U-Net Mini
model_mini = create_model(
    model_type='unet_mini',
    input_shape=(224, 224, 3),
    num_classes=8,
    filters_base=32
)

# VGG16-UNet
model_vgg = create_model(
    model_type='vgg16_unet',
    input_shape=(224, 224, 3),
    num_classes=8,
    freeze_encoder=False  # Permettre l'entra√Ænement du backbone
)

# Compilation avec diff√©rentes fonctions de perte
model_mini = compile_model(model_mini, loss_type='dice_loss')
model_vgg = compile_model(model_vgg, loss_type='combined_loss')
```

### Entra√Ænement avec le Script

```bash
# Entra√Ænement rapide avec U-Net Mini
python train_segmentation.py \
    --model unet_mini \
    --loss dice_loss \
    --epochs 20 \
    --batch_size 32 \
    --augment

# Entra√Ænement performance avec VGG16-UNet
python train_segmentation.py \
    --model vgg16_unet \
    --loss combined_loss \
    --epochs 50 \
    --batch_size 16 \
    --learning_rate 5e-5 \
    --augment
```

## üìä Exemples d'Entra√Ænement

### 1. Validation Rapide (U-Net Mini)
```bash
python train_segmentation.py \
    --model unet_mini \
    --loss cross_entropy \
    --epochs 10 \
    --batch_size 32 \
    --image_size 224
```

### 2. Performance Optimale (VGG16-UNet)
```bash
python train_segmentation.py \
    --model vgg16_unet \
    --loss combined_loss \
    --epochs 50 \
    --batch_size 16 \
    --learning_rate 5e-5 \
    --image_size 224 \
    --augment \
    --validation_split 0.2
```

### 3. Transfer Learning (Backbone Gel√©)
```bash
python train_segmentation.py \
    --model vgg16_unet \
    --loss focal_loss \
    --epochs 30 \
    --freeze_encoder \
    --learning_rate 1e-3 \
    --batch_size 24
```

### 4. Haute R√©solution (ResNet50)
```bash
python train_segmentation.py \
    --model resnet50_unet \
    --loss balanced_cross_entropy \
    --epochs 40 \
    --batch_size 8 \
    --image_size 256 \
    --learning_rate 2e-5
```

## üìÅ Structure des Fichiers

```
‚îú‚îÄ‚îÄ models.py                 # Architectures et fonctions de perte
‚îú‚îÄ‚îÄ train_segmentation.py     # Script d'entra√Ænement principal
‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances Python
‚îú‚îÄ‚îÄ README_models.md          # Documentation (ce fichier)
‚îî‚îÄ‚îÄ models/                   # Dossier pour sauvegarder les mod√®les
    ‚îú‚îÄ‚îÄ best_*.h5            # Meilleurs mod√®les
    ‚îú‚îÄ‚îÄ final_*.h5           # Mod√®les finaux
    ‚îî‚îÄ‚îÄ history_*.png        # Graphiques d'entra√Ænement
```

## üéØ Performances Attendues

### Temps d'Entra√Ænement (par √©poque)

| Mod√®le | Batch Size | Temps/√âpoque | GPU M√©moire |
|--------|------------|--------------|-------------|
| U-Net Mini | 32 | ~2-3 min | ~4 GB |
| VGG16-UNet | 16 | ~5-7 min | ~8 GB |
| ResNet50-UNet | 8 | ~8-12 min | ~12 GB |

### M√©triques de Performance

| Mod√®le | Mean IoU | Accuracy | Param√®tres |
|--------|----------|----------|------------|
| U-Net Mini | ~0.65-0.70 | ~0.85-0.90 | 1.7M |
| VGG16-UNet | ~0.75-0.80 | ~0.90-0.93 | 21M |
| ResNet50-UNet | ~0.78-0.83 | ~0.91-0.94 | 35M |

*Note: Performances indicatives sur Cityscapes, peuvent varier selon le dataset*

## ‚öôÔ∏è Param√®tres Recommand√©s

### Pour D√©butants
```bash
--model unet_mini --loss dice_loss --epochs 20 --batch_size 32
```

### Pour Production
```bash
--model vgg16_unet --loss combined_loss --epochs 50 --batch_size 16 --augment
```

### Pour Recherche
```bash
--model resnet50_unet --loss focal_loss --epochs 100 --batch_size 8 --image_size 256
```

## üîß Personnalisation

### Modifier les Fonctions de Perte

```python
def custom_loss(y_true, y_pred):
    dice = dice_loss(y_true, y_pred)
    focal = focal_loss(y_true, y_pred)
    return 0.7 * dice + 0.3 * focal

# Utilisation
model = compile_model(model, loss_type=custom_loss)
```

### Ajuster l'Architecture

```python
# U-Net avec plus de filtres
model = unet_mini(filters_base=64)  # Plus de capacit√©

# VGG16 avec backbone gel√©
model = vgg16_unet(freeze_encoder=True)  # Transfer learning strict
```

## üìà Suivi de l'Entra√Ænement

Le script g√©n√®re automatiquement :
- **Checkpoints** : Sauvegarde du meilleur mod√®le
- **Graphiques** : Courbes de loss, accuracy, IoU
- **Logs** : M√©triques d√©taill√©es par √©poque

## ü§ù Contribution

1. Tester les mod√®les sur votre dataset
2. Exp√©rimenter avec les fonctions de perte
3. Optimiser les hyperparam√®tres
4. Partager vos r√©sultats et am√©liorations

## üìù Licence

Ce code est fourni √† des fins √©ducatives et de recherche. Veuillez respecter les licences des datasets utilis√©s.

---

**Note**: Ce README accompagne l'impl√©mentation des mod√®les recommand√©s pour r√©duire le temps de traitement et am√©liorer les performances en segmentation s√©mantique.