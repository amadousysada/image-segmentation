# Guide de R√©solution de Probl√®mes - Erreurs de Forme

## ‚ùå Erreur Commune : Incompatibilit√© de Forme

```
ValueError: Arguments `target` and `output` must have the same shape up until the last dimension: 
target.shape=(None, 224, 224), output.shape=(None, 448, 448, 8)
```

## üîç Diagnostic de l'Erreur

Cette erreur indique que :
- **Target (masque)** : forme `(batch, 224, 224)`
- **Output (pr√©diction)** : forme `(batch, 448, 448, 8)`

### Probl√®mes identifi√©s :
1. **Taille spatiale diff√©rente** : 224√ó224 vs 448√ó448
2. **Forme incompatible** : le target n'a pas la dimension des classes

## üõ†Ô∏è Solutions Impl√©ment√©es

### 1. Architecture U-Net Mini Corrig√©e

**Avant (probl√©matique) :**
```python
# 4 downsampling + 4 upsampling + 1 upsampling final = 5 upsampling
x1, skip1 = encoder_block(inputs, filters_base)      # 224‚Üí112
x2, skip2 = encoder_block(x1, filters_base * 2)      # 112‚Üí56  
x3, skip3 = encoder_block(x2, filters_base * 4)      # 56‚Üí28
x4, skip4 = encoder_block(x3, filters_base * 8)      # 28‚Üí14
bottleneck = conv_block(x4, filters_base * 16)       # 14‚Üí7
# Puis 4 decoder + 1 final upsampling = 448x448 ‚ùå
```

**Apr√®s (corrig√©e) :**
```python
# 3 downsampling + 3 upsampling = dimensions √©quilibr√©es
x1, skip1 = encoder_block(inputs, filters_base)      # 224‚Üí112
x2, skip2 = encoder_block(x1, filters_base * 2)      # 112‚Üí56
x3, skip3 = encoder_block(x2, filters_base * 4)      # 56‚Üí28
bottleneck = conv_block(x3, filters_base * 8)        # reste √† 28x28
# Puis 3 decoder steps: 28‚Üí56‚Üí112‚Üí224 ‚úÖ
```

### 2. Architecture VGG16-UNet Corrig√©e

**Avant (probl√©matique) :**
```python
# Skip connections incorrectement dimensionn√©es
skip1 = vgg16.get_layer('block1_conv2').output    # 224x224 (FAUX)
# ... upsampling incorrect conduisant √† 448x448
```

**Apr√®s (corrig√©e) :**
```python
# Skip connections correctement dimensionn√©es  
skip1 = vgg16.get_layer('block1_conv2').output    # 112x112 (apr√®s pooling)
skip2 = vgg16.get_layer('block2_conv2').output    # 56x56
skip3 = vgg16.get_layer('block3_conv3').output    # 28x28  
skip4 = vgg16.get_layer('block4_conv3').output    # 14x14

# D√©codeur avec upsampling s√©quentiel correct
# 7x7 -> 14x14 -> 28x28 -> 56x56 -> 112x112 -> 224x224
```

### 2. Fonctions de Perte Robustes

Toutes les fonctions de perte ont √©t√© mises √† jour avec un redimensionnement automatique :

```python
def dice_loss(y_true, y_pred, smooth=1e-6):
    # Redimensionnement automatique si n√©cessaire
    pred_shape = tf.shape(y_pred)
    true_shape = tf.shape(y_true)
    
    if true_shape[1] != pred_shape[1] or true_shape[2] != pred_shape[2]:
        y_true = tf.image.resize(
            tf.expand_dims(tf.cast(y_true, tf.float32), axis=-1),
            [pred_shape[1], pred_shape[2]], 
            method='nearest'
        )
        y_true = tf.cast(tf.squeeze(y_true, axis=-1), tf.int32)
    # ... reste du calcul
```

### 3. Fonction de D√©bogage

```python
from models import debug_model_output_shape

# V√©rifier la forme de sortie de votre mod√®le
model = create_model('vgg16_unet', (224, 224, 3), 8)
debug_model_output_shape(model)
```

## üöÄ Utilisation Corrig√©e

### Test Rapide
```python
# Importer les mod√®les corrig√©s
from models import create_model, compile_model, dice_loss

# Cr√©er le mod√®le VGG16-UNet corrig√©
model = create_model('vgg16_unet', (224, 224, 3), 8)

# Compiler avec fonction de perte robuste
model = compile_model(model, loss_type='dice_loss')

# Test avec donn√©es factices
import tensorflow as tf
test_image = tf.random.normal((1, 224, 224, 3))
test_mask = tf.random.uniform((1, 224, 224), 0, 8, dtype=tf.int32)

# Pr√©diction (devrait √™tre 224x224 maintenant)
prediction = model(test_image)
print(f"Forme de pr√©diction: {prediction.shape}")  # (1, 224, 224, 8)

# Test de loss (devrait fonctionner)
loss_value = dice_loss(test_mask, prediction)
print(f"Loss: {loss_value}")
```

### Entra√Ænement avec Mod√®les Corrig√©s
```bash
# U-Net Mini (toujours fonctionnel)
python train_segmentation.py --model unet_mini --loss dice_loss --epochs 10

# VGG16-UNet (maintenant corrig√©) 
python train_segmentation.py --model vgg16_unet --loss combined_loss --epochs 20

# ResNet50-UNet (v√©rifi√© et fonctionnel)
python train_segmentation.py --model resnet50_unet --loss focal_loss --epochs 15
```

## üîß Diagnostic Automatique

Utilisez le script de d√©bogage pour identifier les probl√®mes :

```bash
python debug_model_shapes.py
```

Ce script :
- ‚úÖ Teste toutes les architectures de mod√®les
- ‚úÖ V√©rifie les formes de sortie
- ‚úÖ Teste les fonctions de perte avec diff√©rentes tailles
- ‚úÖ Identifie les probl√®mes potentiels
- ‚úÖ Propose des solutions

## üìã Checklist de V√©rification

Avant d'entra√Æner votre mod√®le :

- [ ] **Taille d'entr√©e coh√©rente** : Vos images et masques ont la m√™me taille spatiale
- [ ] **Architecture v√©rifi√©e** : Utilisez `debug_model_output_shape()` 
- [ ] **Fonction de perte compatible** : Utilisez les versions corrig√©es
- [ ] **Test simple** : Cr√©ez des donn√©es factices pour validation

## üéØ Solutions par Type d'Erreur

### Erreur 1: Output trop grand (ex: 448√ó448 au lieu de 224√ó224)
**Solution :** Architecture corrig√©e automatiquement dans `models.py`

### Erreur 2: Formes incompatibles entre masque et pr√©diction  
**Solution :** Fonctions de perte avec redimensionnement automatique

### Erreur 3: Dimensionalit√© incorrecte
**Solution :** V√©rification et conversion automatique des types

### Erreur 4: Probl√®me de batch size
**Solution :** Gestion dynamique des formes avec `tf.shape()`

## üö® Actions d'Urgence

Si vous avez encore des probl√®mes :

1. **Utilisez U-Net Mini** (garanti de fonctionner) :
   ```python
   model = create_model('unet_mini', (224, 224, 3), 8)
   ```

2. **Forcez le redimensionnement** dans votre code :
   ```python
   # Redimensionner le masque pour correspondre √† la pr√©diction
   mask_resized = tf.image.resize(
       tf.expand_dims(tf.cast(mask, tf.float32), -1),
       prediction.shape[1:3], 
       method='nearest'
   )
   mask_resized = tf.cast(tf.squeeze(mask_resized, -1), tf.int32)
   ```

3. **Utilisez la cross-entropy standard** (plus robuste) :
   ```python
   model.compile(
       optimizer='adam',
       loss='sparse_categorical_crossentropy',
       metrics=['accuracy']
   )
   ```

## ‚úÖ Validation de la Correction

Pour confirmer que tout fonctionne :

```python
# Test complet
from models import create_model, compile_model, dice_loss
import tensorflow as tf

# Cr√©er le mod√®le
model = create_model('vgg16_unet', (224, 224, 3), 8)
model = compile_model(model, 'dice_loss')

# Donn√©es de test
images = tf.random.normal((4, 224, 224, 3))
masks = tf.random.uniform((4, 224, 224), 0, 8, dtype=tf.int32)

# Test d'entra√Ænement d'une √©tape  
history = model.fit(images, masks, epochs=1, verbose=1)

print("‚úÖ Tout fonctionne correctement!")
```

---

**Les corrections apport√©es garantissent la compatibilit√© et la robustesse des mod√®les pour tous les cas d'usage.**